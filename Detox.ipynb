{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/esh04/Detoxifier/blob/main/Detox.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "train = pd.read_csv('../dataset/train.csv')\n",
        "test = pd.read_csv('../dataset/test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id                                       comment_text  toxic  \\\n",
              "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
              "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
              "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
              "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
              "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
              "\n",
              "   severe_toxic  obscene  threat  insult  identity_hate  \n",
              "0             0        0       0       0              0  \n",
              "1             0        0       0       0              0  \n",
              "2             0        0       0       0              0  \n",
              "3             0        0       0       0              0  \n",
              "4             0        0       0       0              0  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "#get rid of empty comments\n",
        "train['comment_text'].fillna(\"unknown\", inplace=True)\n",
        "test['comment_text'].fillna(\"unknown\", inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# cleaning the data\n",
        "import re\n",
        "import string\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub('\\[.*?\\]', '', text)\n",
        "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
        "    text = re.sub('<.*?>+', '', text)\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
        "    text = re.sub('\\n', ' ', text)\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "train['text'] = train['comment_text'].apply(lambda x: clean_text(x))\n",
        "test['text'] = test['comment_text'].apply(lambda x: clean_text(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>explanation why the edits made under my userna...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>daww he matches this background colour im seem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>hey man im really not trying to edit war its j...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>more i cant make any real suggestions on impr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>you sir are my hero any chance you remember wh...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id                                       comment_text  toxic  \\\n",
              "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
              "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
              "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
              "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
              "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
              "\n",
              "   severe_toxic  obscene  threat  insult  identity_hate  \\\n",
              "0             0        0       0       0              0   \n",
              "1             0        0       0       0              0   \n",
              "2             0        0       0       0              0   \n",
              "3             0        0       0       0              0   \n",
              "4             0        0       0       0              0   \n",
              "\n",
              "                                                text  \n",
              "0  explanation why the edits made under my userna...  \n",
              "1  daww he matches this background colour im seem...  \n",
              "2  hey man im really not trying to edit war its j...  \n",
              "3   more i cant make any real suggestions on impr...  \n",
              "4  you sir are my hero any chance you remember wh...  "
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment_text</th>\n",
              "      <th>text</th>\n",
              "      <th>tokenized_text</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>explanation why the edits made under my userna...</td>\n",
              "      <td>[explanation, why, the, edits, made, under, my...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>daww he matches this background colour im seem...</td>\n",
              "      <td>[daww, he, matches, this, background, colour, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>hey man im really not trying to edit war its j...</td>\n",
              "      <td>[hey, man, im, really, not, trying, to, edit, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>more i cant make any real suggestions on impr...</td>\n",
              "      <td>[more, i, cant, make, any, real, suggestions, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>you sir are my hero any chance you remember wh...</td>\n",
              "      <td>[you, sir, are, my, hero, any, chance, you, re...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        comment_text  \\\n",
              "0  Explanation\\nWhy the edits made under my usern...   \n",
              "1  D'aww! He matches this background colour I'm s...   \n",
              "2  Hey man, I'm really not trying to edit war. It...   \n",
              "3  \"\\nMore\\nI can't make any real suggestions on ...   \n",
              "4  You, sir, are my hero. Any chance you remember...   \n",
              "\n",
              "                                                text  \\\n",
              "0  explanation why the edits made under my userna...   \n",
              "1  daww he matches this background colour im seem...   \n",
              "2  hey man im really not trying to edit war its j...   \n",
              "3   more i cant make any real suggestions on impr...   \n",
              "4  you sir are my hero any chance you remember wh...   \n",
              "\n",
              "                                      tokenized_text              labels  \n",
              "0  [explanation, why, the, edits, made, under, my...  [0, 0, 0, 0, 0, 0]  \n",
              "1  [daww, he, matches, this, background, colour, ...  [0, 0, 0, 0, 0, 0]  \n",
              "2  [hey, man, im, really, not, trying, to, edit, ...  [0, 0, 0, 0, 0, 0]  \n",
              "3  [more, i, cant, make, any, real, suggestions, ...  [0, 0, 0, 0, 0, 0]  \n",
              "4  [you, sir, are, my, hero, any, chance, you, re...  [0, 0, 0, 0, 0, 0]  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "label_columns = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
        "train['labels'] = train[label_columns].apply(lambda x: list(x), axis=1)\n",
        "\n",
        "train.drop(['id'], inplace=True, axis=1)\n",
        "train.drop(label_columns, inplace=True, axis=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment_text</th>\n",
              "      <th>text</th>\n",
              "      <th>tokenized_text</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>explanation why the edits made under my userna...</td>\n",
              "      <td>[explanation, why, the, edits, made, under, my...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>daww he matches this background colour im seem...</td>\n",
              "      <td>[daww, he, matches, this, background, colour, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>hey man im really not trying to edit war its j...</td>\n",
              "      <td>[hey, man, im, really, not, trying, to, edit, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>more i cant make any real suggestions on impr...</td>\n",
              "      <td>[more, i, cant, make, any, real, suggestions, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>you sir are my hero any chance you remember wh...</td>\n",
              "      <td>[you, sir, are, my, hero, any, chance, you, re...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159566</th>\n",
              "      <td>\":::::And for the second time of asking, when ...</td>\n",
              "      <td>and for the second time of asking when your vi...</td>\n",
              "      <td>[and, for, the, second, time, of, asking, when...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159567</th>\n",
              "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
              "      <td>you should be ashamed of yourself   that is a ...</td>\n",
              "      <td>[you, should, be, ashamed, of, yourself, that,...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159568</th>\n",
              "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
              "      <td>spitzer   umm theres no actual article for pro...</td>\n",
              "      <td>[spitzer, umm, theres, no, actual, article, fo...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159569</th>\n",
              "      <td>And it looks like it was actually you who put ...</td>\n",
              "      <td>and it looks like it was actually you who put ...</td>\n",
              "      <td>[and, it, looks, like, it, was, actually, you,...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159570</th>\n",
              "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
              "      <td>and  i really dont think you understand  i ca...</td>\n",
              "      <td>[and, i, really, dont, think, you, understand,...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>159571 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             comment_text  \\\n",
              "0       Explanation\\nWhy the edits made under my usern...   \n",
              "1       D'aww! He matches this background colour I'm s...   \n",
              "2       Hey man, I'm really not trying to edit war. It...   \n",
              "3       \"\\nMore\\nI can't make any real suggestions on ...   \n",
              "4       You, sir, are my hero. Any chance you remember...   \n",
              "...                                                   ...   \n",
              "159566  \":::::And for the second time of asking, when ...   \n",
              "159567  You should be ashamed of yourself \\n\\nThat is ...   \n",
              "159568  Spitzer \\n\\nUmm, theres no actual article for ...   \n",
              "159569  And it looks like it was actually you who put ...   \n",
              "159570  \"\\nAnd ... I really don't think you understand...   \n",
              "\n",
              "                                                     text  \\\n",
              "0       explanation why the edits made under my userna...   \n",
              "1       daww he matches this background colour im seem...   \n",
              "2       hey man im really not trying to edit war its j...   \n",
              "3        more i cant make any real suggestions on impr...   \n",
              "4       you sir are my hero any chance you remember wh...   \n",
              "...                                                   ...   \n",
              "159566  and for the second time of asking when your vi...   \n",
              "159567  you should be ashamed of yourself   that is a ...   \n",
              "159568  spitzer   umm theres no actual article for pro...   \n",
              "159569  and it looks like it was actually you who put ...   \n",
              "159570   and  i really dont think you understand  i ca...   \n",
              "\n",
              "                                           tokenized_text              labels  \n",
              "0       [explanation, why, the, edits, made, under, my...  [0, 0, 0, 0, 0, 0]  \n",
              "1       [daww, he, matches, this, background, colour, ...  [0, 0, 0, 0, 0, 0]  \n",
              "2       [hey, man, im, really, not, trying, to, edit, ...  [0, 0, 0, 0, 0, 0]  \n",
              "3       [more, i, cant, make, any, real, suggestions, ...  [0, 0, 0, 0, 0, 0]  \n",
              "4       [you, sir, are, my, hero, any, chance, you, re...  [0, 0, 0, 0, 0, 0]  \n",
              "...                                                   ...                 ...  \n",
              "159566  [and, for, the, second, time, of, asking, when...  [0, 0, 0, 0, 0, 0]  \n",
              "159567  [you, should, be, ashamed, of, yourself, that,...  [0, 0, 0, 0, 0, 0]  \n",
              "159568  [spitzer, umm, theres, no, actual, article, fo...  [0, 0, 0, 0, 0, 0]  \n",
              "159569  [and, it, looks, like, it, was, actually, you,...  [0, 0, 0, 0, 0, 0]  \n",
              "159570  [and, i, really, dont, think, you, understand,...  [0, 0, 0, 0, 0, 0]  \n",
              "\n",
              "[159571 rows x 4 columns]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "MAX_LEN = 320\n",
        "TRAIN_BATCH_SIZE = 32\n",
        "VALID_BATCH_SIZE = 32\n",
        "EPOCHS = 2\n",
        "LEARNING_RATE = 1e-05\n",
        "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "print(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MultiLabelDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataframe, tokenizer, max_len, new_data=False):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.text = dataframe.text\n",
        "        self.new_data = new_data\n",
        "        \n",
        "        if not new_data:\n",
        "            self.targets = self.data.labels\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = str(self.text[index])\n",
        "        text = \" \".join(text.split())\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            pad_to_max_length=True,\n",
        "            return_token_type_ids=True\n",
        "        )\n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "        token_type_ids = inputs[\"token_type_ids\"]\n",
        "\n",
        "        out = {\n",
        "            'ids': torch.tensor(ids, dtype=torch.long),\n",
        "            'mask': torch.tensor(mask, dtype=torch.long),\n",
        "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
        "        }\n",
        "        \n",
        "        if not self.new_data:\n",
        "            out['targets'] = torch.tensor(self.targets[index], dtype=torch.float)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "At-9kvkqeLKy",
        "outputId": "527bd7f2-ff29-45c7-ce5b-e3d9c2f97d30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.23.1-py3-none-any.whl (5.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m187.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.5/163.5 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp310-cp310-macosx_10_9_x86_64.whl (197 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m197.6/197.6 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /Users/eshk/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from transformers) (2.28.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /Users/eshk/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /Users/eshk/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from transformers) (1.23.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/eshk/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from transformers) (21.3)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.1-cp310-cp310-macosx_10_11_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m957.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /Users/eshk/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from transformers) (2022.9.13)\n",
            "Collecting filelock\n",
            "  Using cached filelock-3.8.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/eshk/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.3.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/eshk/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/eshk/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/eshk/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from requests->transformers) (1.26.12)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/eshk/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from requests->transformers) (2.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/eshk/opt/anaconda3/envs/nlp/lib/python3.10/site-packages (from requests->transformers) (2022.9.14)\n",
            "Installing collected packages: tokenizers, pyyaml, filelock, huggingface-hub, transformers\n",
            "Successfully installed filelock-3.8.0 huggingface-hub-0.10.1 pyyaml-6.0 tokenizers-0.13.1 transformers-4.23.1\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /Users/eshk/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from transformers import DistilBertTokenizer, DistilBertModel\n",
        "import nltk\n",
        "\n",
        "#tokenizer nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "tokenizer = word_tokenize\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Orig Dataset: (159571, 4)\n",
            "Training Dataset: (127657, 4)\n",
            "Validation Dataset: (31914, 4)\n"
          ]
        }
      ],
      "source": [
        "train_size = 0.8\n",
        "\n",
        "train_df = train.sample(frac=train_size, random_state=123)\n",
        "val_df = train.drop(train_df.index).reset_index(drop=True)\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "\n",
        "\n",
        "print(\"Orig Dataset: {}\".format(train.shape))\n",
        "print(\"Training Dataset: {}\".format(train_df.shape))\n",
        "print(\"Validation Dataset: {}\".format(val_df.shape))\n",
        "\n",
        "\n",
        "training_set = MultiLabelDataset(train_df, tokenizer, MAX_LEN)\n",
        "val_set = MultiLabelDataset(val_df, tokenizer, MAX_LEN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                }\n",
        "\n",
        "val_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "               'shuffle': False,\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "val_loader = DataLoader(val_set, **val_params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(epoch):\n",
        "    for epochs in range(EPOCHS):\n",
        "        model.train()\n",
        "        \n",
        "        for _, data in tqdm(enumerate(training_loader, 0)):\n",
        "            ids = data['ids'].to(DEVICE, dtype=torch.long)\n",
        "            mask = data['mask'].to(DEVICE, dtype=torch.long)\n",
        "            token_type_ids = data['token_type_ids'].to(DEVICE, dtype=torch.long)\n",
        "            targets = data['targets'].to(DEVICE, dtype=torch.float)\n",
        "\n",
        "            outputs = model(ids, mask, token_type_ids)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss = torch.nn.functional.binary_cross_entropy_with_logits(outputs, targets)\n",
        "            \n",
        "            if _ % 5000 == 0:\n",
        "                print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
        "            \n",
        "            loss.backward()\n",
        "            optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "all_test_pred = []\n",
        "\n",
        "def test(epoch):\n",
        "    model.eval()\n",
        "    \n",
        "    with torch.inference_mode():\n",
        "    \n",
        "        for _, data in tqdm(enumerate(test_loader, 0)):\n",
        "\n",
        "\n",
        "            ids = data['ids'].to(DEVICE, dtype=torch.long)\n",
        "            mask = data['mask'].to(DEVICE, dtype=torch.long)\n",
        "            token_type_ids = data['token_type_ids'].to(DEVICE, dtype=torch.long)\n",
        "            outputs = model(ids, mask, token_type_ids)\n",
        "            probas = torch.sigmoid(outputs)\n",
        "\n",
        "            all_test_pred.append(probas)\n",
        "            \n",
        "            \n",
        "    return probas\n",
        "probas = test(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MASK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vp4Z2uS8x_r1",
        "outputId": "0cac7bf0-3256-464b-884a-e5970eb9e902"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at SkolkovoInstitute/roberta_toxicity_classifier were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[   0, 6968,   32, 2770,    2]])\n",
            "SequenceClassifierOutput(loss=None, logits=tensor([[ 4.6567, -4.9115]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "tensor([[9.9993e-01, 6.9912e-05]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([[    0, 29902, 21068,    29,    32, 23584,     2]])\n",
            "SequenceClassifierOutput(loss=None, logits=tensor([[-3.7082,  3.5778]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)\n",
            "0.9993153810501099\n",
            "tensor([[   0, 1322,    2]])\n"
          ]
        }
      ],
      "source": [
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
        "import torch\n",
        "import re\n",
        "\n",
        "# load tokenizer and model weights\n",
        "tokenizer = RobertaTokenizer.from_pretrained('SkolkovoInstitute/roberta_toxicity_classifier')\n",
        "model = RobertaForSequenceClassification.from_pretrained('SkolkovoInstitute/roberta_toxicity_classifier')\n",
        "\n",
        "# # # prepare the input\n",
        "# batch = tokenizer.encode('you are amazing', return_tensors='pt')\n",
        "# print(batch)\n",
        "# print(model(batch))\n",
        "# output = torch.nn.functional.softmax(model(batch).logits, dim = -1)\n",
        "# # inference\n",
        "# print(output)\n",
        "\n",
        "# batch = tokenizer.encode('these clowns are useless', return_tensors='pt')\n",
        "# print(batch)\n",
        "\n",
        "# # print(model.predict('you are of no use at all'))\n",
        "\n",
        "# print(model(batch))\n",
        "# output = torch.nn.functional.softmax(model(batch).logits, dim = -1)\n",
        "# print(float(output[0][1]))\n",
        "\n",
        "# batch = tokenizer.encode('are', return_tensors='pt')\n",
        "# print(batch)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3KTdo7C4pBgW"
      },
      "outputs": [],
      "source": [
        "def mask(sentence):\n",
        "  # for i in range(len(sentence)):\n",
        "  #   if (not sentence[i].isalpha()):\n",
        "  #     sentence[i]=' '\n",
        "  sentence = re.sub(r'[^a-zA-Z]', ' ', sentence)\n",
        "  \n",
        "  sentence = ' ' + sentence + ' '\n",
        "\n",
        "  sentence = sentence.split(' ')\n",
        "\n",
        "  # true_sent = []\n",
        "  # for i in sentence:\n",
        "  #   true_sent.append(i)\n",
        "  # true_sent = sentence\n",
        "  true_sent = sentence.copy()\n",
        "\n",
        "  # print(true_sent)\n",
        "  masked_sentence = ''\n",
        "  min_tox = 1\n",
        "  while True:\n",
        "    for i in range(len(sentence)):\n",
        "\n",
        "      # print('1:',i,sentence)\n",
        "      sentence[i] = '[MASK]'\n",
        "      # print('2:',i,sentence)\n",
        "      sentence = ' '.join(sentence)\n",
        "      batch = tokenizer.encode(sentence, return_tensors='pt')\n",
        "      output = torch.nn.functional.softmax(model(batch).logits, dim = -1)\n",
        "      toxic_score = float(output[0][1])\n",
        "      if min_tox > toxic_score:\n",
        "        min_tox = toxic_score\n",
        "        masked_sentence = sentence\n",
        "\n",
        "      # print('nvwubrb',true_sent)\n",
        "      sentence = true_sent.copy()\n",
        "\n",
        "    \n",
        "    if min_tox < 0.25:\n",
        "      break\n",
        "    \n",
        "    true_sent = masked_sentence\n",
        "    true_sent = true_sent.split(' ')\n",
        "  \n",
        "  return masked_sentence\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hCOu7yCryCp",
        "outputId": "1c16a841-ab1b-4aed-f503-a01fdd722a4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(0.0528, grad_fn=<SelectBackward0>)\n",
            " hey [MASK]   try this get a [MASK] life and stay out of mine   which you know nothing about  \n"
          ]
        }
      ],
      "source": [
        "sent = mask(\"hey loser , try this get a fucking life and stay out of mine , which you know nothing about \")\n",
        "batch = tokenizer.encode(sent, return_tensors ='pt')\n",
        "output = torch.nn.functional.softmax(model(batch).logits,dim = -1)\n",
        "print(output[0][1])\n",
        "print(sent)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.4 ('nlp')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "db9d433ab76aa2bebc7886b62d36feb1292e7830d52ec4e11c27f277e0aea8dc"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
